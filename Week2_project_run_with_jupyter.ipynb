{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week2_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python392jvsc74a57bd019139541173f2e7496b90fa77a7245cc9a93a3b9f9cd20c17f9a4ed8283505bb",
      "display_name": "Python 3.9.2 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.2-final"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf1nNDxb1m_u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3afc4b51-2929-4ed1-b774-71bd4b0e2747"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from time import sleep\n",
        "from random import randint\n",
        "import json\n",
        "import re\n",
        "import sqlite3\n",
        "from selenium import webdriver\n",
        "# Set driver for Chrome\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('-headless')\n",
        "options.add_argument('-no-sandbox')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRtdJJgyp7vl",
        "outputId": "96677912-e181-4ed7-bf15-1bee3846cee3"
      },
      "source": [
        "# Connect with .db file\n",
        "conn = sqlite3.connect('C:/Users/Dang Quang/Desktop/Week2_Project/tiki.db')\n",
        "cur = conn.cursor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC85OMedo4yB"
      },
      "source": [
        "# Get URL function\n",
        "\n",
        "def get_url(url):\n",
        "  driver = webdriver.Chrome('C:/Users/Dang Quang/Desktop/Week2_Project/chromedriver.exe',options=options)\n",
        "  driver.get(url)                                            \n",
        "  html_data = driver.page_source                                 \n",
        "  driver.close()                                                 \n",
        "\n",
        "  soup = BeautifulSoup(html_data, 'html.parser') \n",
        "\n",
        "  return soup\n",
        "#_____________________________________________________________\n",
        "def create_categories_table():\n",
        "  query = \"\"\"\n",
        "      CREATE TABLE IF NOT EXISTS categories (\n",
        "          id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "          name VARCHAR(255),\n",
        "          url TEXT, \n",
        "          parent_id INTEGER, \n",
        "          create_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "      )\n",
        "  \"\"\"\n",
        "  try:\n",
        "      cur.execute(query)\n",
        "      conn.commit()\n",
        "  except Exception as err:\n",
        "      print('ERROR BY CREATE TABLE', err)\n",
        "# create_categories_table()\n",
        "\n",
        "#_____________________________________________________________\n",
        "\n",
        "def create_products_table():\n",
        "  query = \"\"\"\n",
        "      CREATE TABLE IF NOT EXISTS products (\n",
        "          id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "          Product_name TEXT,\n",
        "          price INTEGER,\n",
        "          Image TEXT,\n",
        "          Product_URL TEXT,\n",
        "          Reviews INTEGER,\n",
        "          Stars FLOAT,\n",
        "          Discount TEXT,\n",
        "          tikinow TEXT,\n",
        "          Badge TEXT,\n",
        "          Zero TEXT,\n",
        "          Gift TEXT,\n",
        "          main_id INTEGER,\n",
        "          create_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "      )\n",
        "  \"\"\"\n",
        "  try:\n",
        "      cur.execute(query)\n",
        "      conn.commit()\n",
        "  except Exception as err:\n",
        "      print('ERROR BY CREATE TABLE', err)\n",
        "\n",
        "# create_products_table()\n",
        "\n",
        "#_____________________________________________________________\n",
        "\n",
        "def select_query(query,conn=conn):\n",
        "    return pd.read_sql_query(query, conn)\n",
        "\n",
        "main_categories = [{'Name': 'Điện Thoại - Máy Tính Bảng', 'URL': 'https://tiki.vn/dien-thoai-may-tinh-bang/c1789?src=c.1789.hamburger_menu_fly_out_banner'},\n",
        "{'Name': 'Điện Tử - Điện Lạnh', 'URL': 'https://tiki.vn/tivi-thiet-bi-nghe-nhin/c4221?src=c.4221.hamburger_menu_fly_out_banner'}, \n",
        "{'Name': 'Phụ Kiện - Thiết Bị Số', 'URL': 'https://tiki.vn/thiet-bi-kts-phu-kien-so/c1815?src=c.1815.hamburger_menu_fly_out_banner'},\n",
        "{'Name': 'Laptop - Thiết bị IT', 'URL': 'https://tiki.vn/laptop-may-vi-tinh/c1846?src=c.1846.hamburger_menu_fly_out_banner'},\n",
        "{'Name': 'Máy Ảnh - Quay Phim', 'URL': 'https://tiki.vn/may-anh/c1801?src=c.1801.hamburger_menu_fly_out_banner'}, \n",
        "{'Name': 'Điện Gia Dụng', 'URL': 'https://tiki.vn/dien-gia-dung/c1882?src=c.1882.hamburger_menu_fly_out_banner'}, \n",
        "{'Name': 'Nhà Cửa Đời Sống', 'URL': 'https://tiki.vn/nha-cua-doi-song/c1883?src=c.1883.hamburger_menu_fly_out_banner'}, \n",
        "{'Name': 'Hàng Tiêu Dùng - Thực Phẩm', 'URL': 'https://tiki.vn/bach-hoa-online/c4384?src=c.4384.hamburger_menu_fly_out_banner'}, \n",
        "{'Name': 'Đồ chơi, Mẹ & Bé', 'URL': 'https://tiki.vn/me-va-be/c2549?src=c.2549.hamburger_menu_fly_out_banner'}, \n",
        "{'Name': 'Làm Đẹp - Sức Khỏe', 'URL': 'https://tiki.vn/lam-dep-suc-khoe/c1520?src=c.1520.hamburger_menu_fly_out_banner'},\n",
        "{'Name': 'Thể Thao - Dã Ngoại', 'URL': 'https://tiki.vn/the-thao/c1975?src=c.1975.hamburger_menu_fly_out_banner'},\n",
        "{'Name': 'Xe Máy, Ô tô, Xe Đạp', 'URL': 'https://tiki.vn/o-to-xe-may-xe-dap/c8594?src=c.8594.hamburger_menu_fly_out_banner'},\n",
        "{'Name': 'Hàng quốc tế', 'URL': 'https://tiki.vn/hang-quoc-te/c17166?src=c.17166.hamburger_menu_fly_out_banner'}, \n",
        "{'Name': 'Sách, VPP & Quà Tặng', 'URL': 'https://tiki.vn/nha-sach-tiki/c8322?src=c.8322.hamburger_menu_fly_out_banner'}, \n",
        "{'Name': 'Voucher - Dịch Vụ - Thẻ Cào', 'URL': 'https://tiki.vn/voucher-dich-vu/c11312?src=c.11312.hamburger_menu_fly_out_banner'}]\n",
        "\n",
        "#_____________________________________________________________\n",
        "\n",
        "class Product:\n",
        "    def __init__(self, inp_name, inp_price, inp_img, inp_purl, inp_reviews, inp_stars, inp_discount, inp_tikinow=None, inp_badge=None, inp_zero=None, inp_gift=None, inp_main_id = None):\n",
        "        self.name = inp_name\n",
        "        self.price = inp_price\n",
        "        self.img = inp_img\n",
        "        self.purl = inp_purl\n",
        "        self.reviews = inp_reviews\n",
        "        self.stars = inp_stars\n",
        "        self.discount = inp_discount\n",
        "        self.tikinow = inp_tikinow\n",
        "        self.badge = inp_badge\n",
        "        self.zero = inp_zero\n",
        "        self.gift = inp_gift\n",
        "        self.main_id = inp_main_id\n",
        "    def __repr__(self):\n",
        "         return f\"URL: {self.url}, Parent_ID:{self.parent_id}\"\n",
        "    \n",
        "    def save_product(self):\n",
        "        query = \"\"\"\n",
        "            INSERT INTO products (Product_name, price, Image, Product_URL, Reviews, Stars, Discount, tikinow, Badge, Zero, Gift, main_id)\n",
        "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?);\n",
        "        \"\"\"\n",
        "\n",
        "        val = (self.name,  self.price, self.img, self.purl, self.reviews, self.stars, self.discount, self.tikinow, self.badge, self.zero, self.gift, self.main_id)\n",
        "        try:\n",
        "            cur.execute(query, val)\n",
        "            conn.commit()\n",
        "\n",
        "        except Exception as err:\n",
        "            print('ERROR BY INSERT:', err)\n",
        "\n",
        "#_____________________________________________________________\n",
        "\n",
        "class Category:\n",
        "    def __init__(self, name, url, parent_id=None, cat_id=None):\n",
        "        self.cat_id = cat_id\n",
        "        self.name = name\n",
        "        self.url = url\n",
        "        self.parent_id = parent_id\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"ID: {self.cat_id}, Name: {self.name}, URL: {self.url}, Parent: {self.parent_id}\"\n",
        "\n",
        "    def save_into_db(self):\n",
        "        query = \"\"\"\n",
        "            INSERT INTO categories (name, url, parent_id)\n",
        "            VALUES (?, ?, ?);\n",
        "        \"\"\"\n",
        "        val = (self.name, self.url, self.parent_id)\n",
        "        try:\n",
        "            cur.execute(query, val)\n",
        "            self.cat_id = cur.lastrowid\n",
        "            conn.commit()\n",
        "        except Exception as err:\n",
        "            print('ERROR BY INSERT:', err)\n",
        "\n",
        "#_____________________________________________________________\n",
        "\n",
        "def extract_tiki_info(url, parent_id = None):\n",
        "  \"\"\" Extract info from all products of a specfic category on Tiki website\n",
        "      Input: url\n",
        "      Output: info of products, saved as list of dictionary. If no products shown, return empty list.\n",
        "  \"\"\"\n",
        "  data = []\n",
        "  soup = get_url(url)\n",
        "#   main = soup.find('div', {'data-view-id':'product_list_container'})\n",
        "  products = soup.find_all('a', {'class':'product-item'})\n",
        "  len_products = len(products)\n",
        "  print('Number of products: ' + str(len_products))\n",
        "  for product in products:\n",
        "      try:\n",
        "        name = product.find('div', {'class':'name'}).text\n",
        "        if name[0:2] == 'Ad':                                                   #product name\n",
        "            name = name[2:]\n",
        "\n",
        "        price = int(re.sub('\\.', '', product.find('div', {'class':'price-discount__price'}).text[0:-1])) \n",
        "\n",
        "        img = product.img['src']    \n",
        "                                                                                #product image\n",
        "        purl = product['href']                                                  #url\n",
        "        if 'tiki.vn' in purl:                                                   #some scraped URLs don't contain the Tiki.vn, so this adds them when needed\n",
        "            purl = 'https:' + purl\n",
        "        else:\n",
        "            purl = 'https://tiki.vn' + purl\n",
        "\n",
        "        if product.find('div', {'class':'price-discount__discount'}):           #Price Discount\n",
        "            discount = product.find('div', {'class':'price-discount__discount'}).text\n",
        "        else:\n",
        "            discount = 'No'\n",
        "\n",
        "        if product.find('div', {'class':'badge-service'}).img:                  #TikiNow\n",
        "            tikinow = 'Yes'\n",
        "        else:\n",
        "            tikinow = 'No'\n",
        "\n",
        "        if product.find('div', {'class':'badge-under-price'}).img:              #Re Hon Hoan Tien\n",
        "            badge = 'Yes'\n",
        "        else:\n",
        "            badge = 'No'\n",
        "\n",
        "        if product.find('div', {'class':'badge-benefits'}).img:                 #Hot price badge\n",
        "            zero = 'Yes'\n",
        "        else:\n",
        "            zero = 'No'\n",
        "\n",
        "        if product.find('div', {'class':'review'}):                             #Reviews\n",
        "            reviews = int(product.find('div', {'class':'review'}).text[1:-1])  \n",
        "        else:\n",
        "            reviews = 0\n",
        "\n",
        "        stars = 'Not available'\n",
        "        if product.find('div', {'class':'rating__average'}):\n",
        "            stars = int((re.search(r'\\d{1,3}', product.find('div', {'class':'rating__average'})['style'])).group())/20\n",
        "\n",
        "        gift = 'No'\n",
        "        if product.find('div', {'class':'freegift-list'}):\n",
        "            gift = 'Yes'\n",
        "\n",
        "#*****\n",
        "        main_id = None\n",
        "        if parent_id != None:\n",
        "            main_id = define_main(parent_id)\n",
        "\n",
        "\n",
        "      except Exception as err:\n",
        "          print('There a error when scrapping',err)\n",
        "    #   d = {'Product':name, 'Price':price, 'Image':img, 'Link':purl, 'Reviews':reviews, 'Stars':stars, 'Discount':discount, 'Tikinow':tikinow, 'Badge under price':badge, 'Installment':zero, 'gift':gift, 'Main Category': main_id}\n",
        "      variable = Product(name, price, img, purl, reviews, stars, discount, tikinow, badge, zero, gift, main_id)\n",
        "      variable.save_product()\n",
        "    #   data.append(d)\n",
        "  return len_products\n",
        "\n",
        "#_____________________________________________________________\n",
        "# Get the main_id with product ID or product parent_id\n",
        "\n",
        "def define_main(parent_id):\n",
        "  if parent_id <= 15:\n",
        "      return parent_id\n",
        "  query = f\"\"\"\n",
        "  SELECT parent_id\n",
        "  FROM categories\n",
        "  WHERE id = {parent_id}\n",
        "  \"\"\"\n",
        "  p_id = int(pd.read_sql_query(query,conn).iloc[0][0])\n",
        "  return define_main(p_id)\n",
        "\n",
        "#_____________________________________________________________\n",
        "\n",
        "def scrape_tiki(base_url, parent_id = None):\n",
        "#   result = []\n",
        "  page_number = 1\n",
        "  main, opt = base_url.split('?')\n",
        "  \n",
        "  while page_number < 3:\n",
        "    page = f'?page={page_number}&'\n",
        "    url = main+page+opt\n",
        "    print(\"url =\", url)\n",
        "    len_products = extract_tiki_info(url, parent_id)\n",
        "    if len_products < 48:\n",
        "        page_number = 2\n",
        "    # if len(data)>0:\n",
        "    #   result.extend(data)\n",
        "    # else:\n",
        "    #   break\n",
        "    page_number += 1\n",
        "    sleep(randint(1,2))\n",
        "\n",
        "  # items = pd.DataFrame(data = result, columns = result[0].keys())\n",
        "  # items.to_csv(\"./result2.csv\", index=False)\n",
        "\n",
        "#_____________________________________________________________\n",
        "\n",
        "def can_add_to_cat_set(cat_name,save=False):\n",
        "      if cat_name not in CATEGORY_SET:\n",
        "        if save:\n",
        "          CATEGORY_SET.add(cat_name)\n",
        "          print(f'Added \"{cat_name}\" to CATEGORY_SET')\n",
        "        return True\n",
        "      return False\n",
        "\n",
        "#_____________________________________________________________\n",
        "\n",
        "def get_main_category(main_categories, save_db=False):\n",
        "  result=[]\n",
        "  for i in main_categories:\n",
        "      _=can_add_to_cat_set(i['Name'],save_db)\n",
        "\n",
        "      main_cat = Category(i['Name'],i['URL'])\n",
        "      if save_db:\n",
        "          main_cat.save_into_db()\n",
        "      result.append(main_cat)\n",
        "  return result\n",
        "\n",
        "#_____________________________________________________________\n",
        "\n",
        "def get_sub_categories(parent_category, save_db=False):\n",
        "  parent_url = parent_category.url\n",
        "  result = []\n",
        "\n",
        "  try:\n",
        "      soup = get_url(parent_url)\n",
        "      for a in soup.find_all('a', {'class':'item item--category '}):\n",
        "          name = a.text.strip()\n",
        "          if can_add_to_cat_set(name,save_db): \n",
        "            sub_url = a['href']\n",
        "            cat = Category(name, sub_url, parent_category.cat_id) # we now have parent_id, which is cat_id of parent category\n",
        "            if save_db:\n",
        "                cat.save_into_db()\n",
        "            result.append(cat)\n",
        "  except Exception as err:\n",
        "      print('ERROR IN GETTING SUB CATEGORIES:', err)\n",
        "  return result\n",
        "\n",
        "#_____________________________________________________________\n",
        "\n",
        "def get_all_categories(categories,save_db):\n",
        "  categories = categories.copy()\n",
        "  while len(categories):\n",
        "      cat_to_crawl = categories[0]\n",
        "      print(f'Getting {cat_to_crawl} sub-categories...')\n",
        "      sub_categories = get_sub_categories(cat_to_crawl, save_db=save_db)\n",
        "      print(f'Finished! {cat_to_crawl.name} has {len(sub_categories)} sub-categories')\n",
        "      categories+=sub_categories\n",
        "      del categories[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwbQr7Sk2le8"
      },
      "source": [
        "CATEGORY_SET = set()\n",
        "main_cat_objs = get_main_category(main_categories,save_db=True)\n",
        "get_all_categories(main_cat_objs,save_db=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMLJCWNs4nDK"
      },
      "source": [
        "# cur.execute('DROP TABLE products;')\n",
        "# conn.commit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find all the ID that doesn't appeare on parent_id column when use Left Join (IS NULL) => Lowest level categories\n",
        "\n",
        "query1 = '''\n",
        "WITH lowest_sub as \n",
        "(SELECT a.url as url, a.id as parent, b.id as child\n",
        "FROM categories as a\n",
        "LEFT JOIN categories as b ON a.id = b.parent_id\n",
        "WHERE child IS NULL)\n",
        "\n",
        "SELECT url, parent as id\n",
        "FROM lowest_sub\n",
        "'''\n",
        "pd.read_sql_query(query1,conn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo\n",
        "cur.execute ('''\n",
        "WITH lowest_sub as \n",
        "(SELECT a.url as url, a.id as parent, b.id as child\n",
        "FROM categories as a\n",
        "LEFT JOIN categories as b ON a.id = b.parent_id\n",
        "WHERE child IS NULL)\n",
        "\n",
        "SELECT url, parent as id\n",
        "FROM lowest_sub\n",
        "''')\n",
        "text = cur.fetchall()\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5p5Rtmk3f8r"
      },
      "source": [
        "cur.execute ('''\n",
        "WITH lowest_sub as \n",
        "(SELECT a.url as url, a.id as parent, b.id as child\n",
        "FROM categories as a\n",
        "LEFT JOIN categories as b ON a.id = b.parent_id\n",
        "WHERE child IS NULL)\n",
        "\n",
        "SELECT url, parent as id\n",
        "FROM lowest_sub\n",
        "''')\n",
        "text = cur.fetchall()\n",
        "for i in range(len(text)):\n",
        "    url = text[i][0]\n",
        "    parent_id = text[i][1]\n",
        "    scrape_tiki(url, parent_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query2 = '''\n",
        "SELECT *\n",
        "FROM products\n",
        "'''\n",
        "pd.read_sql_query(query2,conn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count number of products in each Category\n",
        "query3 = '''\n",
        "SELECT COUNT(p.id) as Total, p.main_id, c.name\n",
        "FROM products as p\n",
        "JOIN categories as c ON (c.id = p.main_id)\n",
        "GROUP BY main_id\n",
        "'''\n",
        "pd.read_sql_query(query3,conn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.barplot(data = pd.read_sql_query(query3,conn), x = 'Total', y = 'name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Average price of products in each Category\n",
        "query4 = '''\n",
        "SELECT AVG(p.price) as Average, p.Product_name, c.name as Main_category\n",
        "FROM products as p\n",
        "JOIN categories as c ON (c.id = p.main_id)\n",
        "GROUP BY main_id\n",
        "'''\n",
        "pd.read_sql_query(query4,conn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.barplot(data = pd.read_sql_query(query4,conn), x = 'Average', y = 'Main_category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Most expensive product in each Category\n",
        "query4 = '''\n",
        "SELECT max(p.price) as Most_expensive, p.Product_name, c.name as Main_category\n",
        "FROM products as p\n",
        "JOIN categories as c ON (c.id = p.main_id)\n",
        "GROUP BY main_id\n",
        "'''\n",
        "pd.read_sql_query(query4,conn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.barplot(data = pd.read_sql_query(query4,conn), x = 'Most_expensive', y = 'Main_category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Have 5 stars average and have highest number of rating\n",
        "query5 = '''\n",
        "SELECT max(reviews) as Highest_rating, p.Product_name, c.name as Main_category\n",
        "FROM products as p\n",
        "JOIN categories as c ON (c.id = p.main_id)\n",
        "WHERE p.stars = 5\n",
        "GROUP BY main_id\n",
        "'''\n",
        "pd.read_sql_query(query5,conn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.barplot(data = pd.read_sql_query(query5,conn), x = 'Highest_rating', y = 'Main_category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Average stars of each category\n",
        "query6 = '''\n",
        "SELECT AVG(p.stars) as Average_rating, p.Product_name, c.name as Main_category\n",
        "FROM products as p\n",
        "JOIN categories as c ON (c.id = p.main_id)\n",
        "WHERE p.stars BETWEEN 0 AND 5\n",
        "GROUP BY main_id\n",
        "'''\n",
        "pd.read_sql_query(query6,conn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.barplot(data = pd.read_sql_query(query6,conn), x = 'Average_rating', y = 'Main_category')"
      ]
    }
  ]
}